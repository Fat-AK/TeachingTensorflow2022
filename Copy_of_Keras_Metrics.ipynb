{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fat-AK/TeachingTensorflow2022/blob/main/Copy_of_Keras_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwdhTUX_quMD"
      },
      "source": [
        "# Keras metrics\n",
        "\n",
        "Instead of appending loss values to a list or a numpy array, we usually rely on something more convenient: tf.keras.metrics objects.\n",
        "\n",
        "Keras comes with useful objects that support tracking a variable, such as the loss over an entire epoch, computing the average over all losses efficiently while allowing for graph mode train and test step functions/methods.\n",
        "\n",
        "\n",
        "Let's assume we have one **epoch** with a small dataset that fills only **4 batches**, so to compute the average loss for this epoch, we want to average over four loss values. \n",
        "\n",
        "We can do this with a tf.keras.metrics.Mean object, which has an **update_state** method, that takes a scalar value to take into account for the running average, a **result** method, to obtain the result, and a **reset_states** method that resets the metric (after an epoch and between the training and validation steps).\n",
        "\n",
        "To see what is going on we print the metric's result after each batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xviuS53KquME",
        "outputId": "b788d71a-50db-40e5-a3ca-a71608c41383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: loss: 15.873384475708008\n",
            "Epoch 0: val_loss: 16.585254669189453 \n",
            "\n",
            "Epoch 1: loss: 16.326271057128906\n",
            "Epoch 1: val_loss: 17.245628356933594 \n",
            "\n",
            "Epoch 2: loss: 16.922609329223633\n",
            "Epoch 2: val_loss: 16.337326049804688 \n",
            "\n",
            "Epoch 3: loss: 16.261056900024414\n",
            "Epoch 3: val_loss: 16.288795471191406 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "loss_function = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# instantiate metric object (usually in the model's constructor, i.e. __init__, method)\n",
        "loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "# ITERATING OVER A NUMBER OF EPOCHS:\n",
        "for e in range(4):\n",
        "\n",
        "    # ITERATING OVER TRAINING DATA\n",
        "    for batch in range(1000):\n",
        "\n",
        "        model_output = tf.random.uniform(shape=(4,1))*10\n",
        "        target = tf.random.uniform(shape=(4,1))*10\n",
        "\n",
        "        loss = loss_function(target, model_output)\n",
        "\n",
        "        loss_metric.update_state(values=loss)\n",
        "\n",
        "    tf.print(f\"Epoch {e}: loss: {loss_metric.result()}\")\n",
        "\n",
        "    # RESETTING THE METRICS\n",
        "    loss_metric.reset_states()\n",
        "\n",
        "    # ITERATING OVER VALIDATION DATA\n",
        "    for batch in range(200):\n",
        "\n",
        "        model_output = tf.random.uniform(shape=(4,1))*10\n",
        "\n",
        "        target = tf.random.uniform(shape=(4,1))*10\n",
        "\n",
        "        val_loss = loss_function(target, model_output)\n",
        "\n",
        "        loss_metric.update_state(values=val_loss)\n",
        "\n",
        "    tf.print(f\"Epoch {e}: val_loss: {loss_metric.result()} \\n\")\n",
        "\n",
        "    # RESETTING THE METRIC BEFORE NEXT EPOCH\n",
        "    loss_metric.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pj0LxUYquMG"
      },
      "source": [
        "## Accuracy metrics for binary classification\n",
        "As you see we can use tf.keras.metrics.Mean objects to compute running averages without using numpy or list appends. Keras comes with such metric objects for a number of different metrics that we might use to evaluate our model's performance, such as **BinaryAccuracy** in the context of binary classification and **CategoricalAccuracy** **TopKCategoricalAccuracy** in the context of multi-class classification. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmTXfEuFquMG",
        "outputId": "2e557552-bb47-4360-c45b-454299f83463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: loss: 1.0046213865280151\n",
            "Epoch 0: accuracy: 0.5099999904632568\n",
            "Epoch 0: val_loss: 0.9262159466743469\n",
            "Epoch 0: val_accuracy: 0.5874999761581421 \n",
            "\n",
            "Epoch 1: loss: 0.9797967076301575\n",
            "Epoch 1: accuracy: 0.5229166746139526\n",
            "Epoch 1: val_loss: 0.7920961380004883\n",
            "Epoch 1: val_accuracy: 0.574999988079071 \n",
            "\n",
            "Epoch 2: loss: 1.0067111253738403\n",
            "Epoch 2: accuracy: 0.49166667461395264\n",
            "Epoch 2: val_loss: 1.25363290309906\n",
            "Epoch 2: val_accuracy: 0.4124999940395355 \n",
            "\n",
            "Epoch 3: loss: 1.0154286623001099\n",
            "Epoch 3: accuracy: 0.4937500059604645\n",
            "Epoch 3: val_loss: 0.8198896646499634\n",
            "Epoch 3: val_accuracy: 0.5375000238418579 \n",
            "\n",
            "Epoch 4: loss: 1.0363298654556274\n",
            "Epoch 4: accuracy: 0.49791666865348816\n",
            "Epoch 4: val_loss: 1.026277780532837\n",
            "Epoch 4: val_accuracy: 0.44999998807907104 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# instantiate metric object (usually in the model's constructor, i.e. __init__, method)\n",
        "loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
        "binary_accuracy_metric = tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")\n",
        "loss_function = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# What happens in one epoch in the training loop:\n",
        "\n",
        "# training on train data (4 batches)\n",
        "\n",
        "for e in range(5):\n",
        "    for train_batch in range(100):\n",
        "        target = tf.random.uniform(shape=(4,1),minval=0, maxval=1, dtype=tf.int32)\n",
        "        model_output = tf.random.uniform(shape=(4,1))\n",
        "\n",
        "        loss = loss_function(target, model_output)\n",
        "        # \n",
        "        loss_metric.update_state(values=loss)\n",
        "        binary_accuracy_metric.update_state(target, model_output)\n",
        "    tf.print(f\"Epoch {e}: loss: {loss_metric.result()}\")\n",
        "    tf.print(f\"Epoch {e}: accuracy: {binary_accuracy_metric.result()}\")\n",
        "\n",
        "    # RESETTING METRICS BEFORE EVALUATION\n",
        "    loss_metric.reset_states()\n",
        "    binary_accuracy_metric.reset_states()\n",
        "\n",
        "    for val_batch in range(20):\n",
        "        target = tf.random.uniform(shape=(4,1),minval=0, maxval=1, dtype=tf.int32)\n",
        "        model_output = tf.random.uniform(shape=(4,1))\n",
        "\n",
        "        loss = loss_function(target, model_output)\n",
        "        loss_metric.update_state(values=loss)\n",
        "        binary_accuracy_metric.update_state(target, model_output)\n",
        "\n",
        "    tf.print(f\"Epoch {e}: val_loss: {loss_metric.result()}\")\n",
        "    tf.print(f\"Epoch {e}: val_accuracy: {binary_accuracy_metric.result()} \\n\")\n",
        "\n",
        "# resetting the metric before the next epoch\n",
        "loss_metric.reset_states()\n",
        "binary_accuracy_metric.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY3OxB4FquMH"
      },
      "source": [
        "## Accuracy metrics for multi-class categorization tasks\n",
        "\n",
        "In multi-class classification, we use the **CategoricalCrossentropy** as our loss function. To track the accuracy, we need to use a different keras metric, **CategoricalAccuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywRmZy5equMH",
        "outputId": "578f1e4c-35c1-431d-ba7c-34b54c671c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: loss: 2.3252077102661133\n",
            "Epoch 0: accuracy: 0.10000000149011612\n",
            "Epoch 0: val_loss: 2.3609747886657715\n",
            "Epoch 0: val_accuracy: 0.125 \n",
            "\n",
            "Epoch 1: loss: 2.3456506729125977\n",
            "Epoch 1: accuracy: 0.09749999642372131\n",
            "Epoch 1: val_loss: 2.370378255844116\n",
            "Epoch 1: val_accuracy: 0.0625 \n",
            "\n",
            "Epoch 2: loss: 2.3308346271514893\n",
            "Epoch 2: accuracy: 0.10750000178813934\n",
            "Epoch 2: val_loss: 2.3247058391571045\n",
            "Epoch 2: val_accuracy: 0.15000000596046448 \n",
            "\n",
            "Epoch 3: loss: 2.308459997177124\n",
            "Epoch 3: accuracy: 0.11249999701976776\n",
            "Epoch 3: val_loss: 2.3280162811279297\n",
            "Epoch 3: val_accuracy: 0.11249999701976776 \n",
            "\n",
            "Epoch 4: loss: 2.346121311187744\n",
            "Epoch 4: accuracy: 0.09749999642372131\n",
            "Epoch 4: val_loss: 2.358342170715332\n",
            "Epoch 4: val_accuracy: 0.0625 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# instantiate metric object (usually in the model's constructor, i.e. __init__, method)\n",
        "loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
        "accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "for e in range(5):\n",
        "    for train_batch in range(100):\n",
        "        \n",
        "        # create random one-hot targets (labels)\n",
        "        target = tf.one_hot(tf.random.uniform(minval=0,maxval=9, shape=(4,),dtype=tf.int32), depth=10)\n",
        "\n",
        "        # create random model output (for each element in the batch the values are probabilities that sum to 1)\n",
        "        model_output = tf.nn.softmax(tf.random.uniform(shape=(4,10)), axis=-1)\n",
        "\n",
        "        loss = loss_function(target, model_output)\n",
        "\n",
        "        loss_metric.update_state(values=loss)\n",
        "        accuracy_metric.update_state(target, model_output)\n",
        "    tf.print(f\"Epoch {e}: loss: {loss_metric.result()}\")\n",
        "    tf.print(f\"Epoch {e}: accuracy: {accuracy_metric.result()}\")\n",
        "\n",
        "    # RESETTING METRICS BEFORE EVALUATION\n",
        "    loss_metric.reset_states()\n",
        "    accuracy_metric.reset_states()\n",
        "\n",
        "    for val_batch in range(20):\n",
        "        target = tf.one_hot(tf.random.uniform(minval=0,maxval=9, shape=(4,),dtype=tf.int32), depth=10)\n",
        "        model_output = tf.nn.softmax(tf.random.uniform(shape=(4,10)), axis=-1)\n",
        "\n",
        "        loss = loss_function(target, model_output)\n",
        "        loss_metric.update_state(values=loss)\n",
        "        accuracy_metric.update_state(target, model_output)\n",
        "\n",
        "    tf.print(f\"Epoch {e}: val_loss: {loss_metric.result()}\")\n",
        "    tf.print(f\"Epoch {e}: val_accuracy: {accuracy_metric.result()} \\n\")\n",
        "\n",
        "    # resetting the metric before the next epoch\n",
        "    loss_metric.reset_states()\n",
        "    accuracy_metric.reset_states()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Jh9Q_KquMI"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "- We can use keras metrics instead of tedious numpy loss tracking and metric computations. \n",
        "\n",
        "- Keras metrics can be used with Tensorflow's graph mode, while list appends and numpy operations generally can not\n",
        "\n",
        "- The convenient compile and fit methods of the tf.keras.Model class use keras metrics under the hood. \n",
        "    - Starting to use the metric objects gets us a step closer to being able to use these tools.\n",
        "\n",
        "\n",
        "\n",
        "Next: **Tensorboard for logging**, log all possible kinds of training data to the tensorboard"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "54ff86533a6a943eb33cb0954e5964c6e356fb8134919fff31cf4713965c9c7c"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}